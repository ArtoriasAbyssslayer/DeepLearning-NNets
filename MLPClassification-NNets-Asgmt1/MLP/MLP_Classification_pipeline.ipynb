{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image Classification with MLP Networks\n",
    "# Preliminaries\n",
    "In this notebook I present a method to classify images from two datasets (Intel and Cifar10) using MLP neural networks.\n",
    "The neural networks that would be presented would have both convolutional and dense layers.\n",
    "The convolutional layers purpose is not only to preprocess the image input in order to extract feature maps but to make the network robust to classfication,thus \n",
    "could be able to classify the object represented in image in any pixel-wise position it could be rendered.\n",
    "# Approach\n",
    "This approach is strictly on research basis thus I use pytorch framework to create the networks and I am focusing on different architecures,optimizers,training types(mini-batch training - online training), learning rates in order to end-up to best fit models using a grid-search algorithm with cross-validation(I could use keras-tuner that would be much easier to implement but\n",
    "I don't know how well it works with pytorch models). \n",
    "# Dataset\n",
    "Last but not least I selected two datasets in order to test if a pretrained model could be migrated and get good in classifying other type of images.\n",
    "So, I used cifar10 for training and then I tested it both on Cifar and Intel Image Classification Dataset that I downloaded from Kaggle.\n",
    "# Disclaimers\n",
    "- The time that I had was quite limited because I am in a period that I looking for thesis undertaking.(Edit undertook thesis and working on it)\n",
    "- Pytorch on python3.11 is not even ported today so conda env with python3.8 was used and I lost some time searching if there is any possible way that I could fix this issue. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get ssl-certificate for jupyter-notebook connection enstablishment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ssl \n",
    "ssl._create_default_https_context = ssl._create_unverified_context"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Install dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install -r ../../requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## First Things First - Loading the Datasets\n",
    "This was part of the code was written during preliminary task on knn and ncc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../utils')\n",
    "from data_loader_CIFAR import load_cifar10_iterators,imshow\n",
    "from data_loader_Intel import load_Intel \n",
    "\n",
    "#Load the CIFAR10 dataset\n",
    "loaders_cifar = load_cifar10_iterators()\n",
    "train_loader = loaders_cifar[0]\n",
    "test_loader = loaders_cifar[1]\n",
    "val_loader = loaders_cifar[2]\n",
    "# Cifar Classes\n",
    "classes_cifar = ('plane', 'car', 'bird', 'cat',\n",
    "           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n",
    "# lOAD INTEL DATASET\n",
    "X_train,Y_train,X_test,Y_test,X_check,Y_check = load_Intel()\n",
    "# Intel Classes\n",
    "classes_intel = ('buildings', 'forest', 'glacier', 'mountain', 'sea', 'street')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check If data is imported correctly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import torchvision.utils\n",
    "print(\"CIFAR10\")\n",
    "for images,classes in train_loader:\n",
    "    print('images.shape:', images.shape)\n",
    "    print('classes.shape', classes.shape)\n",
    "    plt.axis('off')\n",
    "    # without normalization\n",
    "    imshow(torchvision.utils.make_grid(images,n_row=8))\n",
    "    plt.figure(2)\n",
    "    #with normalization\n",
    "    plt.imshow(torchvision.utils.make_grid(images,nrow=16).permute((1,2,0)))\n",
    "    break\n",
    "# The same goes for Intel dataset\n",
    "print(\"Intel Dataset\")\n",
    "for images,classes in zip(X_train,Y_train):\n",
    "    \n",
    "    plt.imshow(images[1:32,1:32,:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fisrt is trained a 7-layer MLP simple yet with multiple architecures and tweaks for images\n",
    "* The first four layers that the consist the network are convolutional layers followed by maxpooling layers. Convoluational layers\n",
    "  are basically like applying filters to the image and get the input from regions of the image. Pooling is required to down sample the detection of features in feature maps.\n",
    "  The whole purpose of this process is to make the classification independent from where the object that is classified is located in the image. \n",
    "* After these 4 layers follow 3 dense layers the first get the vectorized input from feature maps and passes it down to lower and lower dimensions in order the last layer to be able using the softmax activation function output the probabilities of class correspondance of the input image.\n",
    "* Reguarding convolutional layers the model 1 has input of 3 channels(RGB of the image) and outputs to 6 features maps and then from 6 feature maps we got 16 using always kenrel size 5. The increment in channels is done to look more for the feature-details of each image and not compress it.\n",
    "* These values were proposed in bibliography as good starting values for the first two convolutions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from model1 import SmallMLP\n",
    "from minimalTrain import minimal_train\n",
    "\n",
    "minimal_train(100,SmallMLP)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from evaluate import eval_model\n",
    "# Load the model that was previously traineds\n",
    "# model = torch.load('model.pt')\n",
    "eval_model(test_loader, model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Second we test an equivalent model with batch normalization layer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from model2 import NetworkBatchNorm\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lastly we test a Dense layer to see how it operates with images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from model3 import DenseMLP"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('segmentation')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "3a2b30898221a9f73744f05efad6ecd0ef65a16605c07e6f8112b0e1c06b5999"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
