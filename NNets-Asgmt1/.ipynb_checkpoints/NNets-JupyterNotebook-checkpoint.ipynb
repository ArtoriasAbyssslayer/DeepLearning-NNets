{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "487d5a0e-0ea8-4eaf-817b-9873e1b19f75",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (3975055487.py, line 17)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"/tmp/ipykernel_21639/3975055487.py\"\u001b[0;36m, line \u001b[0;32m17\u001b[0m\n\u001b[0;31m    from mnist import MNIST as mnist\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "###############################\n",
    "# Tensor stuff\n",
    "##############################\n",
    "data = [[1, 2], [3, 4]]\n",
    "Tensor = torch.tensor(data)\n",
    "\n",
    "def shape(\n",
    "\n",
    "\n",
    "#############################\n",
    "# mnist stuff\n",
    "#############################\n",
    "\n",
    "from mnist import MNIST as mnist\n",
    "# ''' (sum(X.^2,2) - 2 * X*Y.' + sum(Y.^2,2).') '''\n",
    "\n",
    "mnist.temporary_dir = lambda:'/tmp'\n",
    "\n",
    "\n",
    "train_images = mnist.train_images().tolist()\n",
    "train_labels = mnist.train_labes().tolist()\n",
    "\n",
    "\n",
    "assert shape(train_images) == [60000,28,28]\n",
    "assert shape(train_labes) == [60000]\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig,ax = plt.subplots(10,10)  \n",
    "\n",
    "# plotting in 10x10 subplot matrix the mnist dataset\n",
    "for  i in range(10):\n",
    "    for j in range(10):\n",
    "        ax[i][j] = imshow(train_images[10*i + j], cmap = 'Gray' # acess matrix in row major format as the tensor is stored in dataset\n",
    "        ax[i][j].xaxis.set_visible(False)\n",
    "        ax[i][j].yaxis.set_visible(False)\n",
    "                          \n",
    "                          \n",
    "# As we do supervised learning import test portion of mnist dataset\n",
    "                          \n",
    "test_images = mnist.test_images.tolist()\n",
    "test_labes = mnist.test_labes.tolist()\n",
    "                          \n",
    "# Calculate the average pixel value\n",
    "avg_pixel = tensor_sum(train_images) /60000/28/28\n",
    "                          \n",
    "#recentering,rescaling and linerize the matrix\n",
    "                          \n",
    "train_images = [[(avg_pixel) / 256 for row in image for pixel in row] for image in train_images]\n",
    "        \n",
    "test_images = [[(avg_pixel) / 256 for row in image for pixel in row] for image in test_images]\n",
    "\n",
    "assert shape(train_images) == [60000,784]  # now the images are linearized and I check the size of the matrix\n",
    "                \n",
    "assert shape(test_images) == [10000,784] \n",
    "\n",
    "# after this process the avg_pixel_value  should be very close to zero\n",
    "#one_hot_encode images\n",
    "\n",
    "def one_hot_encoder(i: int, num_labels: int = 10)->List[float]:\n",
    "    for j in range(num_labels):\n",
    "        if j==i:\n",
    "            return 1.0\n",
    "        else\n",
    "            return 0.0\n",
    "\n",
    "                          \n",
    "assert one_hot_encoder(3) == [0,0,0,1,0,0,0,0,0,0]\n",
    "assert one_hot_encoder(2,num_labels=5)\n",
    "                          \n",
    "# encode lables\n",
    "train_labels = [one_hot_encoder(label) for label in train_labels]\n",
    "test_labels = [one_hot_encoder(label) for label in test_labels]\n",
    "\n",
    "assert shape(train_labels) == [60000,10]\n",
    "assert shape(train_labels) == [10000,10]\n",
    "                          \n",
    "\n",
    "                          \n",
    "# tqdm fancy progress bar for unix jupyter and ml\n",
    "import tqdm\n",
    "                          \n",
    "                          \n",
    "                          \n",
    "#loop is the training function of the Nnet\n",
    "                          \n",
    "def loop(model: Layer, images: List[Tensor], labels: List[Tensor], )                          \n",
    "                        \n",
    "                        \n",
    "                          \n",
    "# to bypass classification problems at last layer I use softmax\n",
    "                          \n",
    "def softmax(tensor: Tensor)->Tensor:\n",
    "    \"\"\"Softmax for last dimension\"\"\"\n",
    "    if is_1d(tensor):\n",
    "    # Remove the greater \"outlier\" value for numerical stability\n",
    "    largest = max(tensor)\n",
    "    exps = [math.exp(\n",
    "                          \n",
    "def euclidean_vector_distance(X,Y):\n",
    "    for i in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac6f63b9-aa34-4d33-a06b-c789655a0760",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae41f004-133d-446c-a968-ddda81cfb109",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8269bb8a-a16f-46c1-8d04-62988190926a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
